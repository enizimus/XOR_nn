{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Network using Tensorflow for solving XOR function\n",
    "\n",
    "** Introduction : **\n",
    "In this notebook we will go through the steps of making a simple 2-layer neural network that will learn the XOR function. The XOR \n",
    "function, exclusive or, will give us a 1 only if one of the inputs is zero and the other one, in cases of both beeing one or zero \n",
    "it returns zero, as can be seen in the following table. Where x1 and x2 are the inputs to the function and Y the output. We will use this data to train our model on as these cover all the usecases for the function.\n",
    "\n",
    "| x1 | x2 | Y |\n",
    "|:--:|:--:|:-:|\n",
    "|  0 |  0 | 0 |\n",
    "|  0 |  1 | 1 |\n",
    "|  1 |  0 | 1 |\n",
    "|  1 |  1 | 0 |\n",
    "\n",
    "** Implementation : **\n",
    "To start building the model we will use for this function we will first import the following packages:\n",
    "\n",
    "- Tensorflow \n",
    "- Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training data as presented in the table above\n",
    "\n",
    "X_train = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
    "Y_train = np.array([[0.], [1.], [1.], [0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Interactive Session from Tensorflow so that the Session is implicitly part of any call to  $eval()$, that way we dont have to pass the Session variable around making the code easier to read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model ###\n",
    "\n",
    "The neural network model we will be building will be a two layer neural network. Which we can see in the following figure : \n",
    "\n",
    "<img src=\"./images/nn_model_struct.png\" >\n",
    "\n",
    "As we can see from the figure above, the activation function for the hidden layer will be the [ReLU](https://medium.com/tinymind/a-practical-guide-to-relu-b83ca804f1f7) (rectified linear unit) function and for the output layer we will be using the [Sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function) activation. \n",
    "\n",
    "To start building the neural network we will first have to define the variables for the weights $w1$, $w2$ and biases $b1$, $b2$. As we can see from the model structure above the model will have 2 input features $x1$ and $x2$, with :\n",
    "\n",
    "- $n_{in}$ ... number of input features\n",
    "- $n_{hidd}$ ... number of nodes in hidden layer\n",
    "\n",
    "The weight matrices and bias vectors will have the following shapes : \n",
    "\n",
    "- $w_1.shape = (n_{in},n_{hidd})$\n",
    "- $b_1.shape = (1,n_{hidd})$\n",
    "- $w_2.shape = (n_{hidd},1)$\n",
    "- $b_2.shape = (1,1)$\n",
    "\n",
    "To implement this using tensorflow you can use this code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = 2\n",
    "n_hidd = 2\n",
    "\n",
    "w1 = tf.Variable(tf.random_uniform([n_in, n_hidd], -1, 1), trainable=True)\n",
    "b1 = tf.Variable(tf.zeros(n_hidd))\n",
    "w2 = tf.Variable(tf.random_uniform([n_hidd, 1], -1, 1), trainable=True)\n",
    "b2 = tf.Variable(tf.zeros(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to define a so called *placeholder* using tensorflow for the input vector, $x$, and a *placeholder* for the true label vector, $y$, which will be used for computing the cost. The difference between variables and placeholders in tensorflow is that variables need to be initialized by the session before they're used, whereas placeholders are initialized by the session wherever they are run. We define them as follows :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(shape=(None, n_in), dtype=tf.float32) \n",
    "y = tf.placeholder(shape=(None, 1), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the previously defined blocks and start adding them together to build the model presented earlier.\n",
    "\n",
    "To feed the input features to the hidden layer nodes and then to the output layer we will use the following equations : \n",
    "\n",
    "$$z_1 = w_1^Tx + b_1$$\n",
    "$$a_1 = relu(z_1)$$\n",
    "$$z_2 = w_2^Tx + b_2$$\n",
    "$$a_2 = \\sigma(z_2)$$\n",
    "\n",
    "In the above equations we have implemented the activation functions as presented in Figure 1., the tensorflow code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = tf.matmul(x, w1) + b1\n",
    "a1 = tf.nn.relu(z1)\n",
    "z2 = tf.matmul(a1, w2) + b2\n",
    "a2 = tf.sigmoid(z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now completed the forward propagation implementation part of the neural network model. Implementing the cost function and gradient descent, where the learning happens, is the next step. Doing so is pretty easy with tensorflow but reading up on [gradient descent](https://hackernoon.com/gradient-descent-aynk-7cbe95a778da) and coding it yourself would be a very good exercise and is highly recommended. Regarding the gradient descent we need to choose a good learning rate, we will use $0.1$ but you should also try smaller and bigger values to see how the model evolves.\n",
    "\n",
    "As our loss we will implement the following function : \n",
    "\n",
    "$$J = -(y \\cdot log(a2) + (1 - y) \\cdot log(1 - a2))$$\n",
    "\n",
    "And use the gradient descent algorithm to minimize the cost computed over our training examples. To rule out any missconceptions, \"loss\" is used when reffering to a single training example and the \"cost\" is over the entire training set. The tensorflow code for the loss and gradient descent is :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "cost = tf.reduce_mean(-(y*tf.log(a2) + (1-y)*tf.log(1-a2))) \n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we will have to define a variable initializer which will initialize all the variables defined earlier so that they can be used properly by the code we wrote previously. An important note here is that depending on the initialized values for the weights you will be able to observe the cost converging to a relatively high value and staying around that point or you will see the cost converging rapidly to a value close to zero. So if you get a slow convergence first time running, try it again until you hit initial values that allow a much faster convergence.\n",
    "\n",
    "Now we will just need to repeat the gradient descent for a number of iterations, in our case we will run the training for $20000$ iterations and print the cost every $1000$ iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter = 0, Cost = 0.644\n",
      "Iter = 1000, Cost = 0.025\n",
      "Iter = 2000, Cost = 0.010\n",
      "Iter = 3000, Cost = 0.006\n",
      "Iter = 4000, Cost = 0.004\n",
      "Iter = 5000, Cost = 0.003\n",
      "Iter = 6000, Cost = 0.003\n",
      "Iter = 7000, Cost = 0.002\n",
      "Iter = 8000, Cost = 0.002\n",
      "Iter = 9000, Cost = 0.002\n",
      "Iter = 10000, Cost = 0.002\n",
      "Iter = 11000, Cost = 0.001\n",
      "Iter = 12000, Cost = 0.001\n",
      "Iter = 13000, Cost = 0.001\n",
      "Iter = 14000, Cost = 0.001\n",
      "Iter = 15000, Cost = 0.001\n",
      "Iter = 16000, Cost = 0.001\n",
      "Iter = 17000, Cost = 0.001\n",
      "Iter = 18000, Cost = 0.001\n",
      "Iter = 19000, Cost = 0.001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "init.run()\n",
    "\n",
    "cost_list = []\n",
    "for i in range(20000):\n",
    "    train_step.run(feed_dict={x: X_train, y: Y_train})\n",
    "    if i%1000 == 0:\n",
    "        curr_cost = cost.eval(feed_dict={x: X_train, y: Y_train})\n",
    "        print('Iter = {}, Cost = {:.3f}'.format(i, curr_cost))\n",
    "        cost_list.append(curr_cost)\n",
    "        \n",
    "plt.plot(cost_list)\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('iterations (per thousands)')\n",
    "plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now a model that we have trained and made ready for use, so let's test it on some test data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function for calculating the accuracy\n",
    "\n",
    "def calc_acc(y1, y2):\n",
    "    miss = 0\n",
    "    for v1,v2 in zip(y1,y2):\n",
    "        if v1 != v2:\n",
    "            miss += 1\n",
    "    return ((len(y1)-miss)/len(y1))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred\n",
      "[[0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1.]]\n",
      "Y_test\n",
      "[[0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1.]]\n",
      "Accuracy = 100.00 %\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array([[1., 1.], [0., 0.], [1., 0.], [1., 1.], [1., 0], [0., 1.], [0., 0.], [0., 1.], [0., 1.], [1., 1.], [1., 0.]], dtype=np.float32)\n",
    "Y_test = np.array([[0.], [0.], [1.], [0.], [1.], [1.] , [0.], [1.], [1.], [0.], [1.]], dtype=np.float32)\n",
    "\n",
    "y_pred = a2.eval(feed_dict={x: X_test})\n",
    "y_pred = (y_pred > 0.5).astype(np.float32)\n",
    "\n",
    "acc = calc_acc(Y_test, y_pred)\n",
    "print('y_pred')\n",
    "print(y_pred.T)\n",
    "print('Y_test')\n",
    "print(Y_test.T)\n",
    "print('Accuracy = {:.2f} %'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieve a accuracy of 100% which was expected given the number of iterations over our training data. In this case we wanted to achieve overfitting on the training data because it is the only data our model will probably encounter. Let's try now what happens if we plug in some different values than ones and zeros. Lets run the following code : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test\n",
      "[[ 2.  1. -1. -2.]\n",
      " [ 1.  1.  1. -2.]]\n",
      "y_pred\n",
      "[[1. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# test data :\n",
    "\n",
    "X_test = np.array([[2., 1.], [1., 1.], [-1., 1.], [-2., -2.]], dtype=np.float32)\n",
    "y_pred = a2.eval(feed_dict={x: X_test})\n",
    "y_pred = (y_pred > 0.5).astype(np.float32)\n",
    "\n",
    "acc = calc_acc(Y_test, y_pred)\n",
    "\n",
    "print('X_test')\n",
    "print(X_test.T)\n",
    "print('y_pred')\n",
    "print(y_pred.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model has learned to look for the difference of the two input features, if the difference is not equal to zero it outputs a 0 and otherwise a 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
